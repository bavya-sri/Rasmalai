{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmPsIb2luZPRv6PRK5onL1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bavya-sri/Rasmalai/blob/Final/RIDNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Prh0OStwcFpt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,Conv2D,Activation,BatchNormalization,Add,Multiply,Concatenate,GlobalAveragePooling2D\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files=['/content/drive/MyDrive/DataScience/patches-train/train/'+filename for filename in os.listdir('/content/drive/MyDrive/DataScience/patches-train/train/')]\n",
        "test_files=['/content/drive/MyDrive/DataScience/patches-test/test/'+filename for filename in os.listdir('/content/drive/MyDrive/DataScience/patches-test/test/')]"
      ],
      "metadata": {
        "id": "2goXAg38cLw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _parse_function(filename):\n",
        "    '''This function performs adding noise to the image given by Dataset'''\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.cast(image_decoded, tf.float32)/255.\n",
        "\n",
        "    noise_level=np.random.choice(NOISE_LEVELS)\n",
        "    noisy_image=image+tf.random.normal(shape=(40,40,3),mean=0,stddev=noise_level/255)\n",
        "    noisy_image=tf.clip_by_value(noisy_image, clip_value_min=0., clip_value_max=1.)\n",
        "\n",
        "    return noisy_image,image"
      ],
      "metadata": {
        "id": "MttbhIwxcQr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "NOISE_LEVELS=[15,25,50] \n",
        "\n",
        "#Creating the Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(np.array(train_files)) \n",
        "train_dataset = train_dataset.map(_parse_function)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(np.array(test_files))\n",
        "test_dataset = test_dataset.map(_parse_function)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "JJ9lzKWOcS1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(train_dataset)\n",
        "a, b = iterator.get_next()\n",
        "\n",
        "print('Shape of single batch of x : ',a.shape)\n",
        "print('Shape of single batch of y : ',b.shape)"
      ],
      "metadata": {
        "id": "i4qPNxaZcUp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,10,figsize=(20,4))\n",
        "for i in range(10):\n",
        "  axs[i].imshow(a[i])\n",
        "  axs[i].get_xaxis().set_visible(False)\n",
        "  axs[i].get_yaxis().set_visible(False)\n",
        "fig.suptitle('Noisy Images',fontsize=20)\n",
        "plt.show()\n",
        "fig, axs = plt.subplots(1,10,figsize=(20,4))\n",
        "for i in range(10):\n",
        "  axs[i].imshow(b[i])\n",
        "  axs[i].get_xaxis().set_visible(False)\n",
        "  axs[i].get_yaxis().set_visible(False)\n",
        "fig.suptitle('Ground Truth Images',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "noBL9Y7ncWr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patches(file_name,patch_size,crop_sizes):\n",
        "    image = cv2.imread(file_name) \n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    height, width , channels= image.shape\n",
        "    patches = []\n",
        "    for crop_size in crop_sizes: \n",
        "        crop_h, crop_w = int(height*crop_size),int(width*crop_size)\n",
        "        image_scaled = cv2.resize(image, (crop_w,crop_h), interpolation=cv2.INTER_CUBIC)\n",
        "        for i in range(0, crop_h-patch_size+1, patch_size):\n",
        "            for j in range(0, crop_w-patch_size+1, patch_size):\n",
        "              x = image_scaled[i:i+patch_size, j:j+patch_size] \n",
        "              patches.append(x)\n",
        "    return patches\n",
        "\n",
        "def create_image_from_patches(patches,image_shape):\n",
        "  image=np.zeros(image_shape) \n",
        "  patch_size=patches.shape[1]\n",
        "  p=0\n",
        "  for i in range(0,image.shape[0]-patch_size+1,patch_size):\n",
        "    for j in range(0,image.shape[1]-patch_size+1,patch_size):\n",
        "      image[i:i+patch_size,j:j+patch_size]=patches[p] \n",
        "      p+=1\n",
        "  return np.array(image)\n",
        "\n",
        "def predict_fun(model,image_path,noise_level=30):\n",
        "  patches=get_patches(image_path,40,[1])\n",
        "  test_image=cv2.imread(image_path)\n",
        "\n",
        "  patches=np.array(patches)\n",
        "  ground_truth=create_image_from_patches(patches,test_image.shape)\n",
        "\n",
        "  patches = patches.astype('float32') /255.\n",
        "  patches_noisy = patches+ tf.random.normal(shape=patches.shape,mean=0,stddev=noise_level/255) \n",
        "  patches_noisy = tf.clip_by_value(patches_noisy, clip_value_min=0., clip_value_max=1.)\n",
        "  noisy_image=create_image_from_patches(patches_noisy,test_image.shape)\n",
        "\n",
        "  denoised_patches=model.predict(patches_noisy)\n",
        "  denoised_patches=tf.clip_by_value(denoised_patches, clip_value_min=0., clip_value_max=1.)\n",
        "\n",
        "  denoised_image=create_image_from_patches(denoised_patches,test_image.shape)\n",
        "\n",
        "  return patches_noisy,denoised_patches,ground_truth/255.,noisy_image,denoised_image\n",
        "\n",
        "\n",
        "def plot_patches(patches_noisy,denoised_patches):\n",
        "  fig, axs = plt.subplots(2,10,figsize=(20,4))\n",
        "  for i in range(10):\n",
        "\n",
        "    axs[0,i].imshow(patches_noisy[i])\n",
        "    axs[0,i].title.set_text(' Noisy')\n",
        "    axs[0,i].get_xaxis().set_visible(False)\n",
        "    axs[0,i].get_yaxis().set_visible(False)\n",
        "\n",
        "    axs[1,i].imshow(denoised_patches[i])\n",
        "    axs[1,i].title.set_text('Denoised')\n",
        "    axs[1,i].get_xaxis().set_visible(False)\n",
        "    axs[1,i].get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "\n",
        "def plot_predictions(ground_truth,noisy_image,denoised_image):\n",
        "  fig, axs = plt.subplots(1,3,figsize=(15,15))\n",
        "  axs[0].imshow(ground_truth)\n",
        "  axs[0].title.set_text('Ground Truth')\n",
        "  axs[1].imshow(noisy_image)\n",
        "  axs[1].title.set_text('Noisy Image')\n",
        "  axs[2].imshow(denoised_image)\n",
        "  axs[2].title.set_text('Denoised Image')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def PSNR(gt, image, max_value=1):\n",
        "    mse = np.mean((gt - image) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * np.log10(max_value / (np.sqrt(mse)))"
      ],
      "metadata": {
        "id": "MmDVK5v1cbew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EAM(input):\n",
        "\n",
        "  x=Conv2D(64, (3,3), dilation_rate=1,padding='same',activation='relu')(input)\n",
        "  x=Conv2D(64, (3,3), dilation_rate=2,padding='same',activation='relu')(x)\n",
        "\n",
        "  y=Conv2D(64, (3,3), dilation_rate=3,padding='same',activation='relu')(input)\n",
        "  y=Conv2D(64, (3,3), dilation_rate=4,padding='same',activation='relu')(y)\n",
        "\n",
        "  z=Concatenate(axis=-1)([x,y])\n",
        "  z=Conv2D(64, (3,3),padding='same',activation='relu')(z)\n",
        "  add_1=Add()([z, input])\n",
        "\n",
        "  z=Conv2D(64, (3,3),padding='same',activation='relu')(add_1)\n",
        "  z=Conv2D(64, (3,3),padding='same')(z)\n",
        "  add_2=Add()([z,add_1])\n",
        "  add_2 = Activation('relu')(add_2)\n",
        "\n",
        "  z=Conv2D(64, (3,3),padding='same',activation='relu')(add_2)\n",
        "  z=Conv2D(64, (3,3),padding='same',activation='relu')(z)\n",
        "  z=Conv2D(64, (1,1),padding='same')(z)\n",
        "  add_3=Add()([z,add_2])\n",
        "  add_3 = Activation('relu')(add_3)\n",
        "\n",
        "  z = GlobalAveragePooling2D()(add_3)\n",
        "  z = tf.expand_dims(z,1)\n",
        "  z = tf.expand_dims(z,1)\n",
        "  z=Conv2D(4, (3,3),padding='same',activation='relu')(z)\n",
        "  z=Conv2D(64, (3,3),padding='same',activation='sigmoid')(z)\n",
        "  mul=Multiply()([z, add_3])\n",
        "\n",
        "  return mul"
      ],
      "metadata": {
        "id": "8zwFFUnbcftA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RIDNET():\n",
        "\n",
        "  input = Input((40, 40, 3),name='input')\n",
        "  feat_extraction =Conv2D(64, (3,3),padding='same')(input)\n",
        "  eam_1=EAM(feat_extraction)\n",
        "  eam_2=EAM(eam_1)\n",
        "  eam_3=EAM(eam_2)\n",
        "  eam_4=EAM(eam_3)\n",
        "  x=Conv2D(3, (3,3),padding='same')(eam_4)\n",
        "  add_2=Add()([x, input])\n",
        "  \n",
        "  model=Model(input,add_2)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "64fOmtFbcipi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(6908)\n",
        "ridnet = RIDNET()"
      ],
      "metadata": {
        "id": "bUTWQYKzckv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridnet.compile(optimizer=tf.keras.optimizers.Adam(1e-03), loss=tf.keras.losses.MeanAbsoluteError())"
      ],
      "metadata": {
        "id": "zCNpHwuvcqLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridnet.summary()"
      ],
      "metadata": {
        "id": "0v3XP1mMcsIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(ridnet,show_shapes=True,to_file='ridnet.png')"
      ],
      "metadata": {
        "id": "O0a8SG6NcuEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch,lr):\n",
        "  return lr*0.9"
      ],
      "metadata": {
        "id": "Hpp_Yv5rcwq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/DataScience/ridnet.h5\" \n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=False,verbose=0,save_best_only=False) # To save the model if the metric is improved\n",
        "\n",
        "# Tensorbaord \n",
        "logdir = os.path.join(\"logs_ridnet\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")) # Directory for storing the logs that are required for tensorboard\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "lrScheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "callbacks = [cp_callback,tensorboard_callback,lrScheduler]\n",
        "ridnet.fit( train_dataset,shuffle=True,epochs=10,validation_data= test_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "U2af0duyczQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ridnet.fit( train_dataset,shuffle=True,epochs=20,initial_epoch=10,validation_data= test_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "cYbJSvkjc-eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/logs_ridnet /content/drive/MyDrive/CS2/"
      ],
      "metadata": {
        "id": "bO8URWEjdBjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches_noisy,denoised_patches,ground_truth,noisy_image,denoised_image=predict_fun(ridnet,'/content/drive/MyDrive/DataScience/test/102061.jpg',noise_level=25)\n",
        "print('PSNR of Noisy Image : ',PSNR(ground_truth,noisy_image))\n",
        "print('PSNR of Denoised Image : ',PSNR(ground_truth,denoised_image))\n",
        "plot_patches(patches_noisy,denoised_patches)"
      ],
      "metadata": {
        "id": "0PPv2ryWdE7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(ground_truth,noisy_image,denoised_image)"
      ],
      "metadata": {
        "id": "ISXd611LdHV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_res=Model(ridnet.input,ridnet.get_layer('conv2d_49').output)"
      ],
      "metadata": {
        "id": "A69qu5JMdJZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches_noisy,denoised_patches,ground_truth,noisy_image,residual_image=predict_fun(model_res,'/content/drive/MyDrive/DataScience/test/102061.jpg',noise_level=25)"
      ],
      "metadata": {
        "id": "6zJ2-2ujdMEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,3,figsize=(15,15))\n",
        "axs[0].imshow(ground_truth)\n",
        "axs[0].title.set_text('Ground Truth')\n",
        "axs[1].imshow(noisy_image)\n",
        "axs[1].title.set_text('Noisy Image')\n",
        "axs[2].imshow(residual_image)\n",
        "axs[2].title.set_text('Residual Image')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cI-izHYKdN4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}