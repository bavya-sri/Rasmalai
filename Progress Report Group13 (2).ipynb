{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progress Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction to Data & Data Collection:\n",
    "\n",
    "The project is based on Image denoising which is the process of taking away noise from an image. Information will be lost if there is an increase in noise. A digital camera's sensor illumination levels, damaged electrical circuits from heat, faulty memory locations in hardware, or bit errors during data transmission over long distances are a few examples of how noise can occur. Noise is when extra unnecessary pixel values are added to an image, resulting in the loss of information. We have obtained a dataset from University of California Berkeley in order to denoise the image.\n",
    "\n",
    "The dataset we are studying is found at,\n",
    "\n",
    "Data-https://github.com/BIDS/BSDS500 \n",
    "\n",
    "This Dataset  consists of 500 natural images.\n",
    "\n",
    "We plan to answer the following questions-\n",
    "1. How can we remove blind noise from images?\n",
    "2. How can we boost picture processing efficiency?\n",
    "3. How can we enhance photos taken in poor light?\n",
    "4. How do we restore old photos/documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any changes:\n",
    "The scope has not changed since the check-in proposal slides.\n",
    "\n",
    "Noises are present in the real-world photos that are photographed. These noises may emerge for a variety of causes, including unstable electric signals, broken camera sensors, dim illumination, lost data during long-distance data transmission, etc. As a result of noise, the original pixel values are sometimes replaced by random values, which can reduce the quality of the acquired image and result in information loss. Therefore, when it comes to low-level vision tasks and image processing, it is necessary to eliminate these noises from pictures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data:\n",
    "For our problem set,we need clean images, first we collected high quality images from random sources -\n",
    "1. Smartphone Image Denoising Dataset (SIDD)\n",
    "2. Real Low-Light Image Noise Reduction Dataset (RENOIR)\n",
    "3. NINDâ€Š-Natural Image Noise Dataset\n",
    "4. University of california berkeley Segmentation Data Set and Benchmarks 500 (BSDS500)\n",
    "\n",
    "There were four distinct kinds of datasets gathered; the BSDS500 dataset had 500 natural photos, all of which were of good quality. Of the 500 photos, we divided them into 400 train images and 100 test images.then we create patches for each image,We will split each of these images into small patches.because, splitting images into patches and using these patches for training improve model performance in denoising.\n",
    "\n",
    "Then also the images in the dataset are of different sizes,we resize each image in the dataset to equal sizes for each image, patches of 40*40 pixels, 40-stride height, and various crop sizes are created.\n",
    "Since there are 500 total pictures in the dataset, there will be around 85000 patches for training and 21000 patches for the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from google.colab.patches import cv2_imshow as imshow\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from patchify import patchify, unpatchify\n",
    "from google.colab import drive\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler,ReduceLROnPlateau\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, Activation, Flatten, Dense, Input, MaxPooling2D, Add, Reshape, concatenate, AveragePooling2D, Multiply, GlobalAveragePooling2D, UpSampling2D, MaxPool2D,Softmax\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras import initializers, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import imageio as iio\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_blur(data):\n",
    "    dst = cv2.GaussianBlur(data, (35, 35), cv2.BORDER_DEFAULT)\n",
    "    return dst\n",
    "\n",
    "def add_gaussian_noise(data):\n",
    "    mean = (10, 10, 10)\n",
    "    std = (50, 50, 50)\n",
    "    row, col, channel = data.shape\n",
    "    noise = np.random.normal(mean, std, (row, col, channel)).astype('uint8')\n",
    "    return data + noise\n",
    "def patches(img,patch_size):\n",
    "    patches = patchify(img, (patch_size, patch_size, 3), step=patch_size)\n",
    "    return patches\n",
    "\n",
    "# adds salt and pepper noise \n",
    "def add_salt_pepper_noise(data, p=0.05):\n",
    "    rows, columns, channels = data.shape\n",
    "    output = np.zeros(data.shape, np.uint8)\n",
    "    for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        r = np.random.random()\n",
    "        if r < p/2:\n",
    "            output[i][j] = [0, 0, 0]\n",
    "        elif r > p/2 and r <= p:\n",
    "            output[i][j] = [255, 255, 255]\n",
    "        else:\n",
    "            output[i][j] = data[i][j]\n",
    "    return output\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    sizes=[]\n",
    "    fname=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        fname.append(filename)\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            sizes.append(img.shape)\n",
    "    return fname,images,sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,k,s= load_images_from_folder('/content/train/')\n",
    "df = pd.DataFrame()\n",
    "df['filename']=f[:200]\n",
    "noised_data=[]\n",
    "\n",
    "df['ground_truth']=k\n",
    "for i in k:\n",
    "    g=add_gaussian_blur(i)\n",
    "    n=add_gaussian_noise(g)\n",
    "    noised_data.append(n)\n",
    "\n",
    "df['noised_images']=noised_data\n",
    "df['size']=s\n",
    "df['size'].astype(str)\n",
    "df[3][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = ( 400, 200))\n",
    "df.shape\n",
    "y = list(df['size'].value_counts())\n",
    "print(\"y\",y)\n",
    "x1 = df['size'].value_counts().index.tolist()\n",
    "x=x1[1]\n",
    "x=x[:2]\n",
    "print(\"x\",x)\n",
    "plt.bar(x,y)\n",
    "plt.title(\"Images vs Size\")\n",
    "plt.xlabel(\"Size of images\")\n",
    "plt.ylabel(\"No. of images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread('/content/train/'+df.iloc[3][0])\n",
    "fig, axes = plt.subplots(1,2,figsize=(16, 16))\n",
    "axes[0].imshow(df.iloc[3][1])\n",
    "axes[0].set_title('Ground Truth Image')\n",
    "axes[1].imshow(df.iloc[3][2])\n",
    "axes[1].set_title('Noisy Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating patches for Ground Truth Image\n",
    "random_gt_path = df.iloc[3][0]\n",
    "img = cv2.imread('/content/train/'+random_gt_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print('Image shape: {}'.format(img.shape))\n",
    "patches_gt = patches(img,50)\n",
    "print('Patch shape: {}'.format(patches_gt.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating patches for a Noisy Image\n",
    "img = df.iloc[3][2]\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "print('Image shape: {}'.format(img.shape))\n",
    "\n",
    "patches_nsy = patches(img,50)\n",
    "print('Patch shape: {}'.format(patches_nsy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = patches_nsy.shape[0]\n",
    "cols = patches_nsy.shape[1]\n",
    "fig, axs = plt.subplots(rows,cols,figsize=(20,10))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        axs[i][j].imshow(patches_gt[i][j][0])\n",
    "        axs[i][j].get_xaxis().set_visible(False)\n",
    "        axs[i][j].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,5,figsize=(20,10))\n",
    "r = random.sample(range(0, rows), 5)\n",
    "c = random.sample(range(0, cols), 5)\n",
    "fig.suptitle('Train Image Patches',fontweight =\"bold\")\n",
    "for i in range(5):\n",
    "    axs[i].imshow(patches_gt[r[i]][c[i]][0])\n",
    "    axs[i].set_title('Ground Truth Image Patches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,5,figsize=(20,10))\n",
    "for i in range(5):\n",
    "    axs[i].imshow(patches_nsy[r[i]][c[i]][0])\n",
    "    axs[i].set_title('Noisy Image Patches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_red_gt = []\n",
    "mean_blue_gt = []\n",
    "mean_green_gt = []\n",
    "mean_red_nsy = []\n",
    "mean_blue_nsy = []\n",
    "mean_green_nsy = []\n",
    "for i in df['ground_truth']:\n",
    "    img = i\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mean_red_gt.append(np.mean(img[:,:,0]))\n",
    "    mean_green_gt.append(np.mean(img[:,:,1]))\n",
    "    mean_blue_gt.append(np.mean(img[:,:,2]))\n",
    "\n",
    "for j in df['noised_images']:\n",
    "    img = j\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    mean_red_nsy.append(np.mean(img[:,:,0]))\n",
    "    mean_green_nsy.append(np.mean(img[:,:,1]))\n",
    "    mean_blue_nsy.append(np.mean(img[:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_gt = pd.DataFrame()\n",
    "green_gt = pd.DataFrame()\n",
    "blue_gt = pd.DataFrame()\n",
    "red_nsy = pd.DataFrame()\n",
    "green_nsy = pd.DataFrame()\n",
    "blue_nsy = pd.DataFrame()\n",
    "\n",
    "red_gt['Mean Pixel on Ground Truth Images'] = mean_red_gt\n",
    "red_gt['channel'] = 'red'\n",
    "red_nsy['Mean Pixel on  Noisy Images'] = mean_red_nsy\n",
    "red_nsy['channel'] = 'red'\n",
    "\n",
    "green_gt['Mean Pixel on Ground Truth Images'] = mean_green_gt\n",
    "green_gt['channel'] = 'green'\n",
    "green_nsy['Mean Pixel on  Noisy Images'] = mean_green_nsy\n",
    "green_nsy['channel'] = 'green'\n",
    "\n",
    "blue_gt['Mean Pixel on Ground Truth Images'] = mean_blue_gt\n",
    "blue_gt['channel'] = 'blue'\n",
    "blue_nsy['Mean Pixel on  Noisy Images'] = mean_blue_nsy\n",
    "blue_nsy['channel'] = 'blue'\n",
    "\n",
    "concat_gt = pd.concat([red_gt,green_gt,blue_gt],ignore_index=True)\n",
    "concat_nsy = pd.concat([red_nsy,green_nsy,blue_nsy],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = {'color': ['r', 'g', 'b']}\n",
    "sns.FacetGrid(concat_gt,hue='channel',size=5,hue_kws=color).map(sns.distplot,'Mean Pixel on Ground Truth Images',hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.FacetGrid(concat_nsy,hue='channel',size=5,hue_kws=color).map(sns.distplot,'Mean Pixel on  Noisy Images',hist=False).add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2,figsize=(16, 16))\n",
    "fig.suptitle(\"Ground Truth Images\", fontsize = 'x-large' , fontweight = 'bold' )\n",
    "sns.histplot(mean_red_gt,ax=axes[0][0],color='r')\n",
    "sns.distplot(mean_red_gt,ax=axes[0][1],hist=False,color='r')\n",
    "axes[0][0].set_xlabel('Mean Pixels')\n",
    "axes[0][1].set_xlabel('Mean Pixels')\n",
    "\n",
    "sns.histplot(mean_green_gt,ax=axes[1][0],color='g')\n",
    "sns.distplot(mean_green_gt,ax=axes[1][1],hist=False,color='g')\n",
    "axes[1][0].set_xlabel('Mean Pixels')\n",
    "axes[1][1].set_xlabel('Mean Pixels')\n",
    "\n",
    "sns.histplot(mean_blue_gt,ax=axes[2][0],color='b')\n",
    "sns.distplot(mean_blue_gt,ax=axes[2][1],hist=False,color='b')\n",
    "axes[2][0].set_xlabel('Mean Pixels')\n",
    "axes[2][1].set_xlabel('Mean Pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3,2,figsize=(16, 16))\n",
    "fig.suptitle(\"Noisy Images\", fontsize = 'x-large' , fontweight = 'bold' )\n",
    "sns.histplot(mean_red_nsy,ax=axes[0][0],color='r')\n",
    "sns.distplot(mean_red_nsy,ax=axes[0][1],hist=False,color='r')\n",
    "axes[0][0].set_xlabel('Mean Pixels')\n",
    "axes[0][1].set_xlabel('Mean Pixels')\n",
    "\n",
    "sns.histplot(mean_green_nsy,ax=axes[1][0],color='g')\n",
    "sns.distplot(mean_green_nsy,ax=axes[1][1],hist=False,color='g')\n",
    "axes[1][0].set_xlabel('Mean Pixels')\n",
    "axes[1][1].set_xlabel('Mean Pixels')\n",
    "\n",
    "sns.histplot(mean_blue_nsy,ax=axes[2][0],color='b')\n",
    "sns.distplot(mean_blue_nsy,ax=axes[2][1],hist=False,color='b')\n",
    "axes[2][0].set_xlabel('Mean Pixels')\n",
    "axes[2][1].set_xlabel('Mean Pixels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ground_truth=[df.iloc[9][1],df.iloc[99][1],df.iloc[198][1]]\n",
    "sample_noisy=[df.iloc[9][2],df.iloc[99][2],df.iloc[198][2]]\n",
    "fig, axes = plt.subplots(len(sample_ground_truth),3,figsize=(20, 20))\n",
    "for i in range(len(sample_ground_truth)):\n",
    "    img = sample_ground_truth[i]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    resized_img = cv2.resize(img,(512,512))\n",
    "    axes[i][0].imshow(resized_img)\n",
    "    axes[i][0].set_title('Ground Truth Image')\n",
    "    axes[i][1].plot(cv2.calcHist([img],[0],None,[256],[0,256]),color='r')\n",
    "    axes[i][1].plot(cv2.calcHist([img],[1],None,[256],[0,256]),color='g')\n",
    "    axes[i][1].plot(cv2.calcHist([img],[2],None,[256],[0,256]),color='b')\n",
    "    axes[i][1].set_title('Ground Truth Image Histogram')\n",
    "\n",
    "    img = sample_noisy[i]\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    axes[i][2].plot(cv2.calcHist([img],[0],None,[256],[0,256]),color='r')\n",
    "    axes[i][2].plot(cv2.calcHist([img],[1],None,[256],[0,256]),color='g')\n",
    "    axes[i][2].plot(cv2.calcHist([img],[2],None,[256],[0,256]),color='b')\n",
    "    axes[i][2].set_title('Noisy Image Histogram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSIM = [];PSNR = [];\n",
    "for i in tqdm(range(len(df))):\n",
    "    img1 = df.iloc[i][1]\n",
    "    img1 = img1.astype(\"float32\") / 255.0\n",
    "    img2 = df.iloc[i][2]\n",
    "    img2 = img2.astype(\"float32\") / 255.0\n",
    "    SSIM.append(ssim(img1,img2,multichannel=True,data_range=img2.max() - img2.min()))\n",
    "    PSNR.append(psnr(img1,img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(PSNR,kind='kde')\n",
    "ax.set(xlabel='PSNR', ylabel='Density')\n",
    "ax = sns.displot(PSNR)\n",
    "ax.set(xlabel='PSNR', ylabel='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.displot(SSIM,kind='kde')\n",
    "ax.set(xlabel='SSIM', ylabel='Density')\n",
    "ax = sns.displot(SSIM)\n",
    "ax.set(xlabel='SSIM', ylabel='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflection:\n",
    "\n",
    "The most challenging part of the project was collecting the dataset as initially we found images from different datasets from various sources. In a few datasets, images were taken from mobile phones while few other datasets contained images taken from DSLR cameras and also had limited images. Inorder to get higher accuracy we had to choose BSDS500 as it consisted of more than 500 images.\n",
    "In the preliminary analysis we observed that we need more images in order to get more accuracy from our noisy images. Also when the level of noise is too high, the model fails to provide good results. \n",
    "\n",
    "Are there any concrete results you can show at this point? If not, why not?\n",
    "\n",
    "\n",
    "Our biggest problems continue to be hardware, as well as figuring out appropriate algorithms to conduct analyses with.\n",
    "We believe we are on track to finish this project by the end of the semester,and we are having a plan to build a web application of the model and this is definitely worth proceeding with.\n",
    "\n",
    "Given your initial exploration of the data, is it worth proceeding with your project, why? If not, how will you move forward (method, data etc)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "Going forward, we're looking to denoise the images with higher accuracy. Ideally, we're planning on completing one or two a week, which should allow us to hit the deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
