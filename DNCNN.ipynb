{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM4quyQbxNiPwkaR0WWmE/z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bavya-sri/Rasmalai/blob/Final/DNCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aT-pXhmZQKo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input,MaxPool2D,Conv2D,UpSampling2D,Activation,BatchNormalization,Subtract\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.models import Model\n",
        "import datetime\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files=['/content/drive/MyDrive/DataScience/patches-train/train/'+filename for filename in os.listdir('/content/drive/MyDrive/DataScience/patches-train/train/')]\n",
        "test_files=['/content/drive/MyDrive/DataScience/patches-test/test/'+filename for filename in os.listdir('/content/drive/MyDrive/DataScience/patches-test/test/')]"
      ],
      "metadata": {
        "id": "AHsnbUheZdIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _parse_function(filename):\n",
        "    image_string = tf.io.read_file(filename)\n",
        "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
        "    image = tf.cast(image_decoded, tf.float32)/255.\n",
        "\n",
        "    noise_level=np.random.choice(NOISE_LEVELS)\n",
        "    noisy_image=image+tf.random.normal(shape=(40,40,3),mean=0,stddev=noise_level/255)\n",
        "    noisy_image=tf.clip_by_value(noisy_image, clip_value_min=0., clip_value_max=1.)\n",
        "\n",
        "    return noisy_image,image"
      ],
      "metadata": {
        "id": "2fMMA6AIZfOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE=64\n",
        "NOISE_LEVELS=[15,25,50] \n",
        "\n",
        "#Creating the Dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(np.array(train_files)) \n",
        "train_dataset = train_dataset.map(_parse_function)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices(np.array(test_files))\n",
        "test_dataset = test_dataset.map(_parse_function)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "D-hQjCxrZhGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iterator = iter(train_dataset)\n",
        "a, b = iterator.get_next()\n",
        "\n",
        "print('Shape of single batch of x : ',a.shape)\n",
        "print('Shape of single batch of y : ',b.shape)"
      ],
      "metadata": {
        "id": "ce9q9QGIZjAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1,10,figsize=(20,4))\n",
        "for i in range(10):\n",
        "  axs[i].imshow(a[i])\n",
        "  axs[i].get_xaxis().set_visible(False)\n",
        "  axs[i].get_yaxis().set_visible(False)\n",
        "fig.suptitle('Noisy Images',fontsize=20)\n",
        "plt.show()\n",
        "fig, axs = plt.subplots(1,10,figsize=(20,4))\n",
        "for i in range(10):\n",
        "  axs[i].imshow(b[i])\n",
        "  axs[i].get_xaxis().set_visible(False)\n",
        "  axs[i].get_yaxis().set_visible(False)\n",
        "fig.suptitle('Ground Truth Images',fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Eh2WbNPaZlnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_patches(file_name,patch_size,crop_sizes):\n",
        "    image = cv2.imread(file_name) \n",
        "    image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "    height, width , channels= image.shape\n",
        "    patches = []\n",
        "    for crop_size in crop_sizes: \n",
        "        crop_h, crop_w = int(height*crop_size),int(width*crop_size)\n",
        "        image_scaled = cv2.resize(image, (crop_w,crop_h), interpolation=cv2.INTER_CUBIC)\n",
        "        for i in range(0, crop_h-patch_size+1, patch_size):\n",
        "            for j in range(0, crop_w-patch_size+1, patch_size):\n",
        "              x = image_scaled[i:i+patch_size, j:j+patch_size] \n",
        "              patches.append(x)\n",
        "    return patches\n",
        "\n",
        "def create_image_from_patches(patches,image_shape):\n",
        "  image=np.zeros(image_shape) \n",
        "  patch_size=patches.shape[1]\n",
        "  p=0\n",
        "  for i in range(0,image.shape[0]-patch_size+1,patch_size):\n",
        "    for j in range(0,image.shape[1]-patch_size+1,patch_size):\n",
        "      image[i:i+patch_size,j:j+patch_size]=patches[p] \n",
        "      p+=1\n",
        "  return np.array(image)\n",
        "\n",
        "def predict_fun(model,image_path,noise_level=30):\n",
        "  patches=get_patches(image_path,40,[1])\n",
        "  test_image=cv2.imread(image_path)\n",
        "\n",
        "  patches=np.array(patches)\n",
        "  ground_truth=create_image_from_patches(patches,test_image.shape)\n",
        "\n",
        "  patches = patches.astype('float32') /255.\n",
        "  patches_noisy = patches+ tf.random.normal(shape=patches.shape,mean=0,stddev=noise_level/255) \n",
        "  patches_noisy = tf.clip_by_value(patches_noisy, clip_value_min=0., clip_value_max=1.)\n",
        "  noisy_image=create_image_from_patches(patches_noisy,test_image.shape)\n",
        "\n",
        "  denoised_patches=model.predict(patches_noisy)\n",
        "  denoised_patches=tf.clip_by_value(denoised_patches, clip_value_min=0., clip_value_max=1.)\n",
        "\n",
        "  denoised_image=create_image_from_patches(denoised_patches,test_image.shape)\n",
        "\n",
        "  return patches_noisy,denoised_patches,ground_truth/255.,noisy_image,denoised_image\n",
        "\n",
        "\n",
        "def plot_patches(patches_noisy,denoised_patches):\n",
        "  fig, axs = plt.subplots(2,10,figsize=(20,4))\n",
        "  for i in range(10):\n",
        "\n",
        "    axs[0,i].imshow(patches_noisy[i])\n",
        "    axs[0,i].title.set_text(' Noisy')\n",
        "    axs[0,i].get_xaxis().set_visible(False)\n",
        "    axs[0,i].get_yaxis().set_visible(False)\n",
        "\n",
        "    axs[1,i].imshow(denoised_patches[i])\n",
        "    axs[1,i].title.set_text('Denoised')\n",
        "    axs[1,i].get_xaxis().set_visible(False)\n",
        "    axs[1,i].get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "\n",
        "def plot_predictions(ground_truth,noisy_image,denoised_image):\n",
        "  fig, axs = plt.subplots(1,3,figsize=(15,15))\n",
        "  axs[0].imshow(ground_truth)\n",
        "  axs[0].title.set_text('Ground Truth')\n",
        "  axs[1].imshow(noisy_image)\n",
        "  axs[1].title.set_text('Noisy Image')\n",
        "  axs[2].imshow(denoised_image)\n",
        "  axs[2].title.set_text('Denoised Image')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def PSNR(gt, image, max_value=1):\n",
        "    mse = np.mean((gt - image) ** 2)\n",
        "    if mse == 0:\n",
        "        return 100\n",
        "    return 20 * np.log10(max_value / (np.sqrt(mse)))"
      ],
      "metadata": {
        "id": "BqVcstNpZr-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DnCNN():\n",
        "    \n",
        "    input = Input(shape=(40,40,3),name='input')\n",
        "    x = Conv2D(64,kernel_size= (3,3), padding='same',name='conv2d_l1')(input)\n",
        "    x = Activation('relu',name='act_l1')(x)\n",
        "    for i in range(17):\n",
        "        x = Conv2D(64, kernel_size=(3,3), padding='same',name='conv2d_'+str(i))(x)\n",
        "        x = BatchNormalization(axis=-1,name='BN_'+str(i))(x)\n",
        "        x = Activation('relu',name='act_'+str(i))(x)   \n",
        "    x = Conv2D(3, kernel_size=(3,3), padding='same',name='conv2d_l3')(x)\n",
        "    x = Subtract(name='subtract')([input, x])   \n",
        "    model = Model(input,x)\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "kN70t0fDZuV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "dncnn=None\n",
        "dncnn=DnCNN()"
      ],
      "metadata": {
        "id": "FmnlUs2YZ08V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dncnn.compile(optimizer=tf.keras.optimizers.Adam(1e-03), loss=tf.keras.losses.MeanSquaredError())"
      ],
      "metadata": {
        "id": "tWuRbQRqZ3JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dncnn.summary()"
      ],
      "metadata": {
        "id": "YaKSeM0lZ5ME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(dncnn,show_shapes=True,to_file='dncnn.png')"
      ],
      "metadata": {
        "id": "ekmru9HnZ7RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch,lr):\n",
        "  return lr*0.95"
      ],
      "metadata": {
        "id": "Tc_rsPFFZ9Vg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"/content/drive/MyDrive/DataScience/dncnn.h5\" \n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_weights_only=False,verbose=0,save_best_only=False) \n",
        "\n",
        "# Tensorbaord \n",
        "logdir = os.path.join(\"logs_dncnn\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")) \n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "lrScheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "\n",
        "callbacks = [cp_callback,tensorboard_callback,lrScheduler]\n",
        "dncnn.fit( train_dataset,shuffle=True,epochs=10,validation_data= test_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "5RiOseTEZ_6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dncnn.fit( train_dataset,shuffle=True,epochs=30,initial_epoch=10,validation_data= test_dataset,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "zYdYR5a5aibi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/logs_dncnn /content/drive/MyDrive/DataScience/"
      ],
      "metadata": {
        "id": "3NeyIdgJapaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches_noisy,denoised_patches,ground_truth,noisy_image,denoised_image=predict_fun(dncnn,'/content/drive/MyDrive/DataScience/test/102061.jpg',noise_level=25)\n",
        "print('PSNR of Noisy Image : ',PSNR(ground_truth,noisy_image))\n",
        "print('PSNR of Denoised Image : ',PSNR(ground_truth,denoised_image))\n",
        "plot_patches(patches_noisy,denoised_patches)"
      ],
      "metadata": {
        "id": "Zi-10PqKaxIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(ground_truth,noisy_image,denoised_image)"
      ],
      "metadata": {
        "id": "HE6wY0BRa0Ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_name = 'conv2d_l3' # Getting the output from the model just before subtract layer, Thus it gives the resiudues learnt\n",
        "dncnn_res= Model(inputs=dncnn.input, outputs=dncnn.get_layer(layer_name).output) # Creating the model that gives the residual image output for the given noisy image"
      ],
      "metadata": {
        "id": "shlm6f1Ca53l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches_noisy,denoised_patches,ground_truth,noisy_image,residual_image=predict_fun(dncnn_res,'/content/drive/MyDrive/DataScience/test/102061.jpg',noise_level=25)\n",
        "fig, axs = plt.subplots(1,2,figsize=(10,10))\n",
        "axs[0].imshow(noisy_image)\n",
        "axs[0].title.set_text('Noisy Image')\n",
        "axs[1].imshow(residual_image)\n",
        "axs[1].title.set_text('Residual Image')"
      ],
      "metadata": {
        "id": "Oq1PCjica6tC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}